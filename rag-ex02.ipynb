{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c3aa680",
   "metadata": {},
   "source": [
    "# RAG \n",
    "## 2. 로컬에 저장(chroma 파일을 만들고 거기에 저장)\n",
    "1. 문서 내용 읽기\n",
    "    - https://python.langchain.com/v0.2/docs/integrations/document_loaders/\n",
    "1. 문서 분할(쪼개기)\n",
    "    - 문서 분할하지 않으면?\n",
    "        - 토큰 수 초과로 답변을 생성하지 않을 수 있음\n",
    "        - 문서 길이(input)가 길어서 답변 생성에 시간 소요됨 - > 답변 늦어짐\n",
    "1. 임베딩 - 벡터 데이터베이스에 저장\n",
    "1. 질문이 있으면 벡터 데이터베이스에 유사도 검색(코사인 유사도)\n",
    "1. 유사도 검색으로 가져온 문서를 LLM에 질문과 같이 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71894602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "## 1, 2. 문서 Microsoft Word 파일 읽고 분할 한번에 \n",
    "loader = Docx2txtLoader(\"law_1.docx\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "data_list = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "\n",
    "# 3. 임베딩 -> 벡터 데이터베이스에 저장 \n",
    "## 환경변수 읽어오기\n",
    "load_dotenv()\n",
    "\n",
    "## 3-1. 임베딩 \n",
    "embedding = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94c109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x23a47d99900>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## 3-2 벡터 데이터베이스에 저장 \n",
    "## [방법1] inmemory 보통은 인메모리에 저장하지 않음. \n",
    "# database = Chroma.from_documents(\n",
    "#     documents=data_list,\n",
    "#     embedding=embedding,\n",
    "# )\n",
    "\n",
    "## [방법2] 로컬에 저장(chroma 파일을 만들고 거기에 저장) \n",
    "# 한번 실행하면 생기기 때문에 두번 세번 할 필요가 없음.\n",
    "# database = Chroma.from_documents(\n",
    "#     documents=data_list,\n",
    "#     embedding=embedding,\n",
    "#     persist_directory='./chroma',\n",
    "#     collection_name='chroma-law',\n",
    "# )\n",
    "\n",
    "# 2.1 두번째부터는 로컬에 저장된 임베딩 데이터 가져오기\n",
    "database = Chroma(\n",
    "    embedding_function=embedding,        \n",
    "    persist_directory='./chroma',                  \n",
    "    collection_name='chroma-law',\n",
    ")\n",
    "\n",
    "database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5be48a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='전세사기피해자로 인정받기 위한 조건은 다음과 같습니다:\\n\\n1. 임차인으로서 주택임대차보호법 제3조에 따라 주택의 인수와 주민등록을 마치고, 임대차계약서에 대한 확정일자를 갖추거나, 임차권등기를 마친 상태여야 합니다(임차권등기 또는 전세권 설정이 포함됨).\\n\\n2. 임차보증금이 5억 원 이하이어야 하며, 필요 시 시·도별 피해 상황에 따라 상한액이 2억 원으로 조정될 수 있습니다.\\n\\n3. 임대인의 파산, 회생절차 개시, 경매 또는 공매절차 개시 등으로 인해 임차보증금 반환이 어려운 피해를 입었거나 예상되는 상태여야 합니다. 또한, 다수의 임차인에게 채권반환이 어려운 경우도 포함됩니다.\\n\\n4. 임대인 또는 관련자에 대한 수사 개시, 기망 행위, 임차보증금을 반환할 능력이 없는 자에게 주택을 양도하거나 임차보증금을 반환할 능력 없이 다수의 주택을 취득 또는 임대하는 등의 임대인이 임차보증금 반환 채무를 이행하지 아니할 의사가 의심될 만한 상당한 이유가 있어야 합니다.\\n\\n추가로, 일부 경우(임차인 임차보증금 반환을 위한 보증보험 가입 또는 임차보증금 전액이 최우선변제 가능한 경우 등)에는 전세사기피해자로 인정받지 않을 수 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 352, 'prompt_tokens': 3137, 'total_tokens': 3489, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_38343a2f8f', 'id': 'chatcmpl-BduNHhZF0RdZm8Wn4vnrC2RiRVZzT', 'finish_reason': 'stop', 'logprobs': None}, id='run--fef2601b-c9e1-4dbf-b1ea-44b9bd4c0ff0-0', usage_metadata={'input_tokens': 3137, 'output_tokens': 352, 'total_tokens': 3489, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "## 4. 사용자 질문 + 벡터 데이터베이스에서 유사도 검색\n",
    "# \"전세사기피해자 금융지원에 대해 설명해주세요.\"\n",
    "query = \"전세사기피해자로 인정받기 위한 조건은? \" \n",
    "\n",
    "\n",
    "## 벡터 데이터베이스에서 유사도 검색(기본이 4개씩)\n",
    "retrieved_docs = database.similarity_search(query=query, k=3)\n",
    "\n",
    "\n",
    "## 5. 유사도 검색으로 가져온 문서를 LLM에 질문과 같이 전달 \n",
    "## 5-1 프롬프트 작성\n",
    "prompt = '''\n",
    "[identity]\n",
    "-당신은 전세사기피해 법률 전문가입니다\n",
    "-[context]를 참고해 사용자의 질문에 답변해주세요. \n",
    "\n",
    "[context]\n",
    "{retrieved_docs} \n",
    "\n",
    "Question : {query}\n",
    "\n",
    "'''\n",
    "\n",
    "formatted_prompt = prompt.format(\n",
    "    retrieved_docs=retrieved_docs,\n",
    "    query=query,\n",
    ")\n",
    "\n",
    "## 5-2 LLM 모델 생성, ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    model_name='gpt-4.1-nano'\n",
    ")\n",
    "\n",
    "aimessage = llm.invoke(formatted_prompt)\n",
    "aimessage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
